<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>GPU显存分析 - SongLei&#39;s Blog</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="SongLei" /><meta name="description" content="PyTorch训练显存爆炸的问题：在ImageNet 1k上训练ViT时，遇到了显存爆炸的问题，所以以ViT的训练为例，分析一下显存的占用和优化。
" /><meta name="keywords" content="AI, Sim2Real" />






<meta name="generator" content="Hugo 0.85.0 with theme even" />


<link rel="canonical" href="https://songlei.me/post/code/gpu%E6%98%BE%E5%AD%98%E5%88%86%E6%9E%90/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.f92fd13721ddf72129410fd8250e73152cc6f2438082b6c0208dc24ee7c13fc4.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:title" content="GPU显存分析" />
<meta property="og:description" content="PyTorch训练显存爆炸的问题：在ImageNet 1k上训练ViT时，遇到了显存爆炸的问题，所以以ViT的训练为例，分析一下显存的占用和优化。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://songlei.me/post/code/gpu%E6%98%BE%E5%AD%98%E5%88%86%E6%9E%90/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2021-08-24T00:00:00+00:00" />
<meta property="article:modified_time" content="2021-08-24T00:00:00+00:00" />

<meta itemprop="name" content="GPU显存分析">
<meta itemprop="description" content="PyTorch训练显存爆炸的问题：在ImageNet 1k上训练ViT时，遇到了显存爆炸的问题，所以以ViT的训练为例，分析一下显存的占用和优化。"><meta itemprop="datePublished" content="2021-08-24T00:00:00+00:00" />
<meta itemprop="dateModified" content="2021-08-24T00:00:00+00:00" />
<meta itemprop="wordCount" content="2441">
<meta itemprop="keywords" content="PyTorch,GPU," /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="GPU显存分析"/>
<meta name="twitter:description" content="PyTorch训练显存爆炸的问题：在ImageNet 1k上训练ViT时，遇到了显存爆炸的问题，所以以ViT的训练为例，分析一下显存的占用和优化。"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Song Lei&#39;s blog</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/me/">
        <li class="mobile-menu-item">Me</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Song Lei&#39;s blog</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/me/">Me</a>
      </li>
  </ul>
</nav>

    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">GPU显存分析</h1>

      <div class="post-meta">
        <span class="post-time"> 2021-08-24 </span>
        <div class="post-category">
            <a href="/categories/pytorch/"> PyTorch </a>
            <a href="/categories/gpu/"> GPU </a>
            </div>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content always-active">
    <nav id="TableOfContents">
  <ul>
    <li><a href="#1-gpu中存了什么">1. GPU中存了什么</a></li>
    <li><a href="#2-优化方法">2. 优化方法</a></li>
    <li><a href="#3-具体例子">3. 具体例子</a></li>
    <li><a href="#4-数值化的例子">4. 数值化的例子</a></li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <p>PyTorch训练显存爆炸的问题：在ImageNet 1k上训练ViT时，遇到了显存爆炸的问题，所以以ViT的训练为例，分析一下显存的占用和优化。</p>
<h1 id="1-gpu中存了什么">1. GPU中存了什么</h1>
<p>首先分析是什么占用了显存。主要是初始化、数据、模型、模型forward时保存的梯度信息、其他小变量(如loss什么)等。</p>
<ol>
<li>初始化：GPU初始化需要占用的显存，根据我的测试，不同GPU初始化需要的显存大小不同，我的1060需要583M左右，而服务器上的V100需要1449M左右，这部分无法优化。初始化显存的意思是，即使只是执行<code>a = torch.randn((1, 1)).to('cuda')</code>命令，显存的占用可能达到几百M，这其中只有极少是张量a占用的，绝大部分都是GPU初始化的占用。</li>
<li>数据：CV中的图像输入，一张(3, 224, 224)的图像以float32的方式存储时，大小约为$3<em>224</em>224*4/1000/1000=0.6M$，通常batchsize=32时，一个batch的数据大小约为20M。这部分占用显存比较小，但也可以优化，比如使用更小的精度。</li>
<li>模型：模型大小也不会太大，一般一两百兆，比如ViT。</li>
<li>模型forward时保存的梯度信息：这部分是占用显存最多的地方。</li>
<li>其他小的变量，比如loss等，这部分变量占用显存很少，但如果错误操作，也会造成很大的问题。</li>
</ol>
<h1 id="2-优化方法">2. 优化方法</h1>
<ol>
<li>对数据的优化：使用更小精度的存储，比如每个像素的范围是0-255，但float32的范围远大于这个，所以可以用float16存储，或者混合精度优化等。</li>
<li>模型大小的优化：一般来说模型不会过大，如果需要执行极大的模型，优化时可以采用Model Parallel的方式。</li>
<li>模型forward时保存的梯度信息：这部分需要注意的是在评估时一定要加<code>torch.no_grad()</code>，加了之后评估时不会保存梯度信息，会节省很多内存。</li>
<li>主要是loss变量，如果需要存储loss，比如计算整个数据集上的总loss，或最后画loss曲线，需要注意计算总loss不能直接使用<code>total += loss</code>，画曲线不能直接使用<code>loss_list.append(loss)</code>，而是要用<code>total_loss += loss.item()</code>，<code>loss_list.append(loss.item())</code>。第一种如果直接用<code>total += loss</code>，则会在显存中一直保存一个逐渐增大的计算图，导致内存爆炸，第二个也是类似，由于每轮的loss都保存在列表中，导致loss占的显存不会释放，造成显存浪费。</li>
<li>及时删除无用的变量，这个具体看下面例子的第三点。</li>
</ol>
<h1 id="3-具体例子">3. 具体例子</h1>
<p>比如我有一段这样的代码：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span>  <span class="nf">validate</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">):</span>
	<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
	<span class="n">ret_acc</span> <span class="o">=</span> <span class="n">AverageMeter</span><span class="p">()</span>
	<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span> <span class="ow">in</span>  <span class="nb">enumerate</span><span class="p">(</span><span class="n">val_loader</span><span class="p">):</span>
		<span class="n">batch_size</span> <span class="o">=</span> <span class="n">samples</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
		<span class="n">samples</span> <span class="o">=</span> <span class="n">samples</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>
		<span class="n">targets</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>
		<span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
		<span class="n">acc</span> <span class="o">=</span> <span class="n">accuracy</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
		<span class="n">ret_acc</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">acc</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
	<span class="k">return</span> <span class="n">ret_acc</span>

<span class="k">def</span>  <span class="nf">train</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>
	<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span>  <span class="nb">range</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="s1">&#39;epochs&#39;</span><span class="p">]):</span>
		<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
		<span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>
		<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span> <span class="ow">in</span>  <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
			<span class="n">samples</span> <span class="o">=</span> <span class="n">samples</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>
			<span class="n">targets</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>
			<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
			<span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
			<span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span>
			
			<span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
			<span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
			<span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
		<span class="n">acc</span> <span class="o">=</span> <span class="n">validate</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">)</span>
		<span class="nb">print</span><span class="p">(</span><span class="n">acc</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p>看起来很正常的代码，但存在一些问题：</p>
<ol>
<li><code>evaluate</code>函数中，没有使用<code>torch.no_grad()</code>，这会导致评估时，模型依然保留梯度信息，造成很大的浪费。注意使用了<code>model.eval()</code>不等于<code>no_grad()</code>，model.eval()会让模型中的一些层切换到eval模式，例如BN和dropout，而no_grad()能够关闭反向传播，在forward时不记录梯度信息，减少显存的使用，并加速forward，二者是不一样的。</li>
<li><code>train</code>函数中，计算<code>total_loss</code>时，使用了<code>total_loss += loss</code>，这会导致我们一直保存了一个全是加法的计算图，每个epoch结束时，都会在这个计算图上增加一个加法节点，浪费很多显存。</li>
<li>比较隐蔽的一点，<code>train</code>函数中调用<code>valuate</code>函数前，这里刚刚完成了循环，但python语言中，循环中创建的变量例如<code>sample</code>和<code>target</code>，在循环外依然可以使用，这就导致了虽然看起来循环已经结束，但变量<code>sample</code>和<code>target</code>在GPU上占的显存依然无法释放(因为代码中还可以使用这两个变量，引用计数不是0)，也会造成显存浪费，所以需要手动<code>del</code>无用变量。
这一点看起来可以无关紧要，但如果仔细计算一下，假设batch_size为256，图像大小为(3, 224, 224)，则<code>sample</code>占用的显存为$256<em>3</em>224<em>224</em>4/1000/1000=154M$，其实已经很大了，如果可以释放掉这部分数据，则可以为之后的<code>evaluate</code>函数中的数据空出位置，这样很多时候可以解决训练时显存勉强足够，但评估时显存爆炸的问题。</li>
</ol>
<p>修改后如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span>  <span class="nf">validate</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">):</span>
	<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
	<span class="n">ret_acc</span> <span class="o">=</span> <span class="n">AverageMeter</span><span class="p">()</span>
	<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span> <span class="ow">in</span>  <span class="nb">enumerate</span><span class="p">(</span><span class="n">val_loader</span><span class="p">):</span>
		<span class="n">batch_size</span> <span class="o">=</span> <span class="n">samples</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
		<span class="n">samples</span> <span class="o">=</span> <span class="n">samples</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>
		<span class="n">targets</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>
		<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
			<span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
		<span class="n">acc</span> <span class="o">=</span> <span class="n">accuracy</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
		<span class="n">ret_acc</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">acc</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
	<span class="k">return</span> <span class="n">ret_acc</span>

<span class="k">def</span>  <span class="nf">train</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>
	<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span>  <span class="nb">range</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="s1">&#39;epochs&#39;</span><span class="p">]):</span>
		<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
		<span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>
		<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span> <span class="ow">in</span>  <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
			<span class="n">samples</span> <span class="o">=</span> <span class="n">samples</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>
			<span class="n">targets</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>
			<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
			<span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
			<span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
			
			<span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
			<span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
			<span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
		<span class="k">del</span> <span class="n">sample</span>
		<span class="k">del</span> <span class="n">target</span>
		<span class="k">del</span> <span class="n">loss</span>
		<span class="n">acc</span> <span class="o">=</span> <span class="n">validate</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">)</span>
		<span class="nb">print</span><span class="p">(</span><span class="n">acc</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><h1 id="4-数值化的例子">4. 数值化的例子</h1>
<p>这部分主要是从数值上直观理解第一步说的GPU中存储的各种数据的大小。</p>
<p>在笔记本的1060显卡上测试，模型是ViT，ViT设置如下，数据是CIFAR100，batchsize为32。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="n">model</span> <span class="o">=</span> <span class="n">ViT</span><span class="p">(</span>
	<span class="n">image_size</span><span class="o">=</span><span class="mi">224</span><span class="p">,</span>
	<span class="n">patch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
	<span class="n">num_classes</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>	
	<span class="n">dim</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>	
	<span class="n">depth</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>	
	<span class="n">heads</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
	<span class="n">mlp_dim</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
	<span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
	<span class="n">emb_dropout</span><span class="o">=</span><span class="mf">0.1</span>
<span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><ol>
<li>显存初始化时，使用显存为583M。</li>
<li>加载模型，模型大小是140M左右，加载后显存占用为723M。</li>
<li>加载一个batchsize后，显存为743M，然后我对图像做了mixup增强，然后显存增加到763M。</li>
<li>进行一次forward后，显存占用为1669M，也就是说，forward存储的梯度大约有900M。</li>
<li>评估数据，因为按照上面的讲的做了优化，所以<code>evaluate</code>函数调用时显存基本没有增加。</li>
<li>第二次forward后，显存占用变为2099M，之后基本维持稳定。这里增加的显存我猜测是优化器存储的梯度信息。</li>
</ol>
<p>总结上面的结果，初始化占用583M(这部分对于GPU应该是很恒定的，模型数据更多时也不会变大)，模型占用140M，数据占用20M，forward占用900M，优化器占用400M。forward和优化器占用最多，模型和数据反而是小部分。</p>
    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content">SongLei</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        2021-08-24
        
    </span>
  </p>
  
  
</div>
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/pytorch/">PyTorch</a>
          <a href="/tags/gpu/">GPU</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/ai/nas%E8%B0%83%E7%A0%94/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">AutoML调研</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/note/datadrivenevolutionaryoptimiz_ch5/">
            <span class="next-text nav-default">DataDrivenEvolutionaryOptimiz ch5</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="mailto:your@email.com" class="iconfont icon-email" title="email"></a>
      <a href="https://github.com/s974534426" class="iconfont icon-github" title="github"></a>
  <a href="https://songlei.me/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div>
  <center>本站已经开心运行<span id="runtime_span"></span></center>
  
  <script type="text/javascript">
    function show_runtime() {
      window.setTimeout("show_runtime()", 1000);
      start_time = new Date("03/01/2021 00:00:00");
      cur_time = new Date();
      run_time = cur_time.getTime()-start_time.getTime();
      TIME_PER_DAY=24*60*60*1000;
      day = run_time / TIME_PER_DAY;
      floor_day = Math.floor(day);
      hour = (day - floor_day) * 24;
      floor_hour = Math.floor(hour);
      minute = (hour - floor_hour) * 60;
      floor_minute = Math.floor(minute);
      floor_second = Math.floor((minute - floor_minute)*60);
      runtime_span.innerHTML = floor_day+"天"+floor_hour+"小时"+floor_minute+"分"+floor_second+"秒"
    } show_runtime();
  </script>
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2020 - 
    2021<span class="heart"><i class="iconfont icon-heart"></i></span><span>Song Lei</span>
  </span>
</div>






    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.c99b103c33d1539acf3025e1913697534542c4a5aa5af0ccc20475ed2863603b.js"></script>
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        tags: 'ams',
        }
    };
  </script>
  <script async src="https://cdn.jsdelivr.net/npm/mathjax@3.0.5/es5/tex-mml-chtml.js" integrity="sha256-HGLuEfFcsUJGhvB8cQ8nr0gai9EucOOaIxFw7qxmd+w=" crossorigin="anonymous"></script>








</body>
</html>
